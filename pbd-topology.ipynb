{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "import unos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=(14,8)\n",
    "\n",
    "global_config = {    \n",
    "    'n_samples': 5000,\n",
    "    'n_features': 47,\n",
    "    'n_experiments': 1,\n",
    "    \n",
    "    'train_portion': 0.8,    \n",
    "    'n_hidden_units_per_layer': 200,\n",
    "    'batch_size': 128,\n",
    "    'n_repetitions': 5000, \n",
    "    \n",
    "    'dropout_keep_input': 0.8,\n",
    "    'dropout_keep_hidden': 0.8,\n",
    "    'log_level': 50\n",
    "}\n",
    "\n",
    "global_config['n_train'] = floor(global_config['n_samples'] * global_config['train_portion'])\n",
    "global_config['n_test'] = global_config['n_samples'] - global_config['n_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    p = np.array(p)\n",
    "    return -p * np.log(p) - (1.0-p) * np.log(1.0-p)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def init_weights_xavier(shape):\n",
    "    initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "    return tf.Variable(initializer(shape=shape))\n",
    "\n",
    "def compute_PEHE(TE_true, TE_predict):\n",
    "    return np.sqrt(np.mean(np.abs(TE_true-TE_predict)**2))\n",
    "\n",
    "def estimate_propensities(Dataset):\n",
    "    X_train = Dataset.drop(['Treatment','Response','TE'],axis=1)\n",
    "    y_train = Dataset['Treatment']\n",
    "    logmodel     = LogisticRegression()\n",
    "    logmodel.fit(X_train,y_train)\n",
    "    PScores      = logmodel.predict_proba(X_train)\n",
    "    Propensities = np.transpose(PScores)[1,]\n",
    "    Dataset['Propensity'] = Propensities\n",
    "    Dataset['Entropy']    = -Propensities*np.log(Propensities)-(1-Propensities)*np.log(1-Propensities)\n",
    "    return Dataset\n",
    "\n",
    "def parse_result_list(result_list, exp_name):\n",
    "    avg_pehe_train = np.mean([np.min(res['pehe_train_vals']) for res in result_list])\n",
    "    std_pehe_train = np.std([np.min(res['pehe_train_vals']) for res in result_list])\n",
    "    avg_pehe_test = np.mean([np.min(res['pehe_test_vals']) for res in result_list])\n",
    "    std_pehe_test = np.std([np.min(res['pehe_test_vals']) for res in result_list])\n",
    "\n",
    "    print(\"{}:\".format(exp_name))\n",
    "    print(\"\\t Train: Mean={0:.5f}, Std={1:.5f})\\t\\tTest: Mean={2:.5f} Std={3:.5f}\".format(avg_pehe_train, std_pehe_train, avg_pehe_test, std_pehe_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN-4 Dropout (with 2 outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NN_4_multi_4s(X, weights, p_keep_input, p_keep_hidden):\n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    \n",
    "    # 1st hidden layer (Shared)\n",
    "    h1 = tf.nn.relu(tf.matmul(X, weights['w_h1']))\n",
    "    h1 = tf.nn.dropout(h1, p_keep_hidden)\n",
    "    \n",
    "    # 2nd hidden layer (Shared)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, weights['w_h2']))\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    \n",
    "    # 3rd hidden layer (Shared)\n",
    "    h3 = tf.nn.relu(tf.matmul(h2, weights['w_h3']))\n",
    "    h3 = tf.nn.dropout(h3, p_keep_hidden)\n",
    "    \n",
    "    # 4th hidden layer (Shared)\n",
    "    h4 = tf.nn.relu(tf.matmul(h3, weights['w_h4']))\n",
    "    h4 = tf.nn.dropout(h4, p_keep_hidden)\n",
    "    \n",
    "    # Output\n",
    "    Y_0_out = tf.matmul(h4, weights['w_out_0']) \n",
    "    Y_1_out = tf.matmul(h4, weights['w_out_1'])\n",
    "    \n",
    "    return Y_0_out, Y_1_out\n",
    "\n",
    "def NN_4_multi_2s_2i(X, weights, p_keep_input, p_keep_hidden):\n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    \n",
    "    # 1st hidden layer (Shared)\n",
    "    h1 = tf.nn.relu(tf.matmul(X, weights['w_h1']))\n",
    "    h1 = tf.nn.dropout(h1, p_keep_hidden)\n",
    "    \n",
    "    # 2nd hidden layer (Shared)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, weights['w_h2']))\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    \n",
    "    # 3rd hidden layer (idiosyncratic for Y0)\n",
    "    h3 = tf.nn.relu(tf.matmul(h2, weights['w_h3']))\n",
    "    h3 = tf.nn.dropout(h3, p_keep_hidden)\n",
    "    \n",
    "    # 4th hidden layer (idiosyncratic for Y1)\n",
    "    h4 = tf.nn.relu(tf.matmul(h2, weights['w_h4']))\n",
    "    h4 = tf.nn.dropout(h4, p_keep_hidden)\n",
    "    \n",
    "    # Output\n",
    "    Y_0_out = tf.matmul(h3, weights['w_out_0']) \n",
    "    Y_1_out = tf.matmul(h4, weights['w_out_1'])\n",
    "    \n",
    "    return Y_0_out, Y_1_out\n",
    "\n",
    "def NN_4_multi_2s_4i(X, weights, p_keep_input, p_keep_hidden):\n",
    "    X = tf.nn.dropout(X, p_keep_input)\n",
    "    \n",
    "    # 1st hidden layer (Shared)\n",
    "    h1 = tf.nn.relu(tf.matmul(X, weights['w_h1']))\n",
    "    h1 = tf.nn.dropout(h1, p_keep_hidden)\n",
    "    \n",
    "    # 2nd hidden layer (Shared)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, weights['w_h2']))\n",
    "    h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    \n",
    "    # 3rd hidden layer  (idiosyncratic for Y0) -- 1\n",
    "    h3 = tf.nn.relu(tf.matmul(h2, weights['w_h3']))\n",
    "    h3 = tf.nn.dropout(h3, p_keep_hidden)\n",
    "    \n",
    "    # 3rd hidden layer (idiosyncratic for Y0)  -- 2\n",
    "    h3_2 = tf.nn.relu(tf.matmul(h3, weights['w_h3_2']))\n",
    "    h3_2 = tf.nn.dropout(h3_2, p_keep_hidden)\n",
    "    \n",
    "    # 4th hidden layer (idiosyncratic for Y1) -- 1\n",
    "    h4 = tf.nn.relu(tf.matmul(h2, weights['w_h4']))\n",
    "    h4 = tf.nn.dropout(h4, p_keep_hidden)\n",
    "    \n",
    "    # 4th hidden layer (idiosyncratic for Y1) -- 2\n",
    "    h4_2 = tf.nn.relu(tf.matmul(h4, weights['w_h4_2']))\n",
    "    h4_2 = tf.nn.dropout(h4_2, p_keep_hidden)\n",
    "    \n",
    "    \n",
    "    # Output\n",
    "    Y_0_out = tf.matmul(h3_2, weights['w_out_0']) \n",
    "    Y_1_out = tf.matmul(h4_2, weights['w_out_1'])\n",
    "    \n",
    "    return Y_0_out, Y_1_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_nn4_multi(dataset_train, dataset_test, no_dropout=False, show_log=False, architecture='4s'):\n",
    "    \n",
    "    # Define Placeholders and Init Weights\n",
    "    X = tf.placeholder(\"float\", [None, global_config['n_features']])\n",
    "    Y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    p_keep_input = tf.placeholder(\"float\")\n",
    "    p_keep_hidden = tf.placeholder(\"float\")\n",
    "\n",
    "    Y_0         = tf.placeholder(\"float\", shape=[None, 1])       # Task 1 output\n",
    "    Y_1         = tf.placeholder(\"float\", shape=[None, 1])       # Task 2 output\n",
    "\n",
    "    weights = {\n",
    "        'w_h1': init_weights_xavier([global_config['n_features'], global_config['n_hidden_units_per_layer']]),\n",
    "        'w_h2': init_weights_xavier([global_config['n_hidden_units_per_layer'], global_config['n_hidden_units_per_layer']]),\n",
    "        'w_h3': init_weights_xavier([global_config['n_hidden_units_per_layer'], global_config['n_hidden_units_per_layer']]),\n",
    "        'w_h3_2': init_weights_xavier([global_config['n_hidden_units_per_layer'], global_config['n_hidden_units_per_layer']]),\n",
    "        'w_h4': init_weights_xavier([global_config['n_hidden_units_per_layer'], global_config['n_hidden_units_per_layer']]),\n",
    "        'w_h4_2': init_weights_xavier([global_config['n_hidden_units_per_layer'], global_config['n_hidden_units_per_layer']]),\n",
    "        'w_out_0': init_weights_xavier([global_config['n_hidden_units_per_layer'], 1]),\n",
    "        'w_out_1': init_weights_xavier([global_config['n_hidden_units_per_layer'], 1])\n",
    "    }\n",
    "\n",
    "    # Parse Shared Layers Flag\n",
    "    if architecture == '4s':\n",
    "        pred_Y0, pred_Y1 = NN_4_multi_4s(X, weights, p_keep_input, p_keep_hidden)\n",
    "    elif architecture == '4s_2i':\n",
    "        pred_Y0, pred_Y1 = NN_4_multi_2s_2i(X, weights, p_keep_input, p_keep_hidden) \n",
    "    elif architecture == '4s_4i':\n",
    "        pred_Y0, pred_Y1 = NN_4_multi_2s_4i(X, weights, p_keep_input, p_keep_hidden) \n",
    "    else: \n",
    "        raise Exception('Invalid architecture passed ({})'.format(architecture))\n",
    "\n",
    "    cost0     = tf.nn.l2_loss(Y_0-pred_Y0)\n",
    "    cost1     = tf.nn.l2_loss(Y_1-pred_Y1)\n",
    "\n",
    "    optim0    = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost0)\n",
    "    optim1    = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost1)\n",
    "    \n",
    "    # Prepare Datasets\n",
    "    X_train = dataset_train.drop(['Response', 'TE', 'Treatment', 'Propensity', 'Entropy'], axis=1).as_matrix() \n",
    "    TE_train = np.reshape(dataset_train['TE'].as_matrix(), [global_config['n_train'], 1])\n",
    "\n",
    "    X_test = dataset_test.drop(['Response', 'TE', 'Treatment', 'Propensity', 'Entropy'], axis=1).as_matrix() \n",
    "    TE_test = np.reshape(dataset_test['TE'].as_matrix(), [global_config['n_test'], 1])\n",
    "\n",
    "\n",
    "    \n",
    "    Y_train = np.reshape(dataset_train['Response'].as_matrix(), [global_config['n_train'], 1])\n",
    "    Y_test = np.reshape(dataset_test['Response'].as_matrix(), [global_config['n_test'], 1])\n",
    "    \n",
    "    # Parse Dropout Flag\n",
    "    if no_dropout:\n",
    "        dropout_keep_input = 1.0\n",
    "        dropout_keep_hidden = 1.0\n",
    "    else:\n",
    "        dropout_keep_input = global_config['dropout_keep_input']\n",
    "        dropout_keep_hidden = global_config['dropout_keep_hidden']\n",
    "        \n",
    "    \n",
    "    # Start Training\n",
    "    mses_train_0 = []\n",
    "    mses_train_1 = []\n",
    "\n",
    "    pehes_train = []\n",
    "    pehes_test = []\n",
    "\n",
    "    Y0_loss = 0\n",
    "    Y1_loss = 0\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        for i in range(global_config['n_repetitions']):\n",
    "            if i%2 == 0:\n",
    "                _, Y0_loss = sess.run([optim0, cost0], feed_dict= {\n",
    "                              X  : X_train[dataset_train['Treatment']==0], \n",
    "                              Y_0: Y_train[dataset_train['Treatment']==0],\n",
    "                              p_keep_input: dropout_keep_input,\n",
    "                              p_keep_hidden: dropout_keep_hidden})\n",
    "            else:\n",
    "                _, Y1_loss = sess.run([optim1, cost1], feed_dict= {\n",
    "                              X  : X_train[dataset_train['Treatment']==1], \n",
    "                              Y_1: Y_train[dataset_train['Treatment']==1],\n",
    "                              p_keep_input: dropout_keep_input,\n",
    "                              p_keep_hidden: dropout_keep_hidden})\n",
    "\n",
    "            # Compute Training Error\n",
    "            mses_train_0.append(Y0_loss)\n",
    "            mses_train_1.append(Y1_loss)\n",
    "\n",
    "\n",
    "            # Predict TE\n",
    "            Y0_predict_train = sess.run(pred_Y0, feed_dict={X: X_train, p_keep_input: 1.0,\n",
    "                              p_keep_hidden: 1.0})\n",
    "            Y1_predict_train = sess.run(pred_Y1, feed_dict={X: X_train, p_keep_input: 1.0,\n",
    "                              p_keep_hidden: 1.0})\n",
    "\n",
    "            TE_true_train               = TE_train\n",
    "            TE_predict_train            = np.array(Y1_predict_train)-np.array(Y0_predict_train)\n",
    "\n",
    "            Y0_predict_test = sess.run(pred_Y0, feed_dict={X: X_test, p_keep_input: 1.0,\n",
    "                              p_keep_hidden: 1.0})\n",
    "            Y1_predict_test = sess.run(pred_Y1, feed_dict={X: X_test, p_keep_input: 1.0,\n",
    "                              p_keep_hidden: 1.0})\n",
    "\n",
    "            TE_true_test               = TE_test\n",
    "            TE_predict_test            = np.array(Y1_predict_test)-np.array(Y0_predict_test)\n",
    "\n",
    "            # Compute PEHE\n",
    "            pehe_train = compute_PEHE(TE_true_train, TE_predict_train)\n",
    "            pehes_train.append(pehe_train)\n",
    "\n",
    "            pehe_test = compute_PEHE(TE_true_test, TE_predict_test)\n",
    "            pehes_test.append(pehe_test)\n",
    "\n",
    "            if show_log and i % global_config['log_level'] == 0:\n",
    "                print('#{}. \\tMSE Y0: {} \\tMSE Y1: {}\\t PEHE: {}'.format(i, Y0_loss, Y1_loss, pehe_train))\n",
    "\n",
    "        sess.close()\n",
    "\n",
    "    result_dict = {\n",
    "        \"pehe_train_vals\": pehes_train,\n",
    "        \"pehe_test_vals\": pehe_test\n",
    "    }\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment 1/1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0. \tMSE Y0: 239979040.0 \tMSE Y1: 0\t PEHE: 619.3606611225365\n",
      "#50. \tMSE Y0: 223232000.0 \tMSE Y1: 4947439.5\t PEHE: 597.2304286808493\n",
      "#100. \tMSE Y0: 220099424.0 \tMSE Y1: 3534865.5\t PEHE: 594.8369720221921\n",
      "#150. \tMSE Y0: 219919184.0 \tMSE Y1: 2935722.0\t PEHE: 591.0437950816522\n",
      "#200. \tMSE Y0: 218839456.0 \tMSE Y1: 2342159.25\t PEHE: 578.0364037425782\n",
      "#250. \tMSE Y0: 201000592.0 \tMSE Y1: 1771882.125\t PEHE: 536.271800523079\n",
      "#300. \tMSE Y0: 167628048.0 \tMSE Y1: 1536571.875\t PEHE: 496.7190337420423\n",
      "#350. \tMSE Y0: 202233408.0 \tMSE Y1: 1378588.625\t PEHE: 444.63547321927575\n",
      "#400. \tMSE Y0: 65786340.0 \tMSE Y1: 1487918.875\t PEHE: 388.64657727139246\n",
      "#450. \tMSE Y0: 26467518.0 \tMSE Y1: 1271527.625\t PEHE: 321.09173268570964\n",
      "#500. \tMSE Y0: 20482666.0 \tMSE Y1: 942609.3125\t PEHE: 358.54115250068145\n",
      "#550. \tMSE Y0: 90210784.0 \tMSE Y1: 1030732.75\t PEHE: 342.1905229932621\n",
      "#600. \tMSE Y0: 23108088.0 \tMSE Y1: 1011266.875\t PEHE: 379.0913909145026\n",
      "#650. \tMSE Y0: 30512728.0 \tMSE Y1: 1117144.25\t PEHE: 392.0800096562538\n",
      "#700. \tMSE Y0: 17741312.0 \tMSE Y1: 825119.0\t PEHE: 397.82153162603083\n",
      "#750. \tMSE Y0: 51242504.0 \tMSE Y1: 948159.625\t PEHE: 386.22718284489696\n",
      "#800. \tMSE Y0: 34023692.0 \tMSE Y1: 834439.375\t PEHE: 386.73498846063893\n",
      "#850. \tMSE Y0: 30774716.0 \tMSE Y1: 881386.8125\t PEHE: 398.3200901327499\n",
      "#900. \tMSE Y0: 19662084.0 \tMSE Y1: 789610.875\t PEHE: 389.18112842182865\n",
      "#950. \tMSE Y0: 21842804.0 \tMSE Y1: 815821.375\t PEHE: 389.97399949453313\n",
      "#1000. \tMSE Y0: 13487004.0 \tMSE Y1: 801257.4375\t PEHE: 395.5604078902219\n",
      "#1050. \tMSE Y0: 10100311.0 \tMSE Y1: 708405.5\t PEHE: 397.2185693314696\n",
      "#1100. \tMSE Y0: 18637896.0 \tMSE Y1: 728989.375\t PEHE: 396.8947000306453\n",
      "#1150. \tMSE Y0: 9799790.0 \tMSE Y1: 734342.125\t PEHE: 389.1275500843899\n",
      "#1200. \tMSE Y0: 57158792.0 \tMSE Y1: 836748.25\t PEHE: 390.4726396253955\n",
      "#1250. \tMSE Y0: 20328830.0 \tMSE Y1: 646115.1875\t PEHE: 394.6113343724402\n",
      "#1300. \tMSE Y0: 36087292.0 \tMSE Y1: 707951.6875\t PEHE: 392.8400793307236\n",
      "#1350. \tMSE Y0: 21905002.0 \tMSE Y1: 682863.8125\t PEHE: 394.79101876722484\n",
      "#1400. \tMSE Y0: 42994852.0 \tMSE Y1: 663311.5\t PEHE: 392.8338764322382\n",
      "#1450. \tMSE Y0: 11454820.0 \tMSE Y1: 704739.3125\t PEHE: 397.01151586713246\n",
      "#1500. \tMSE Y0: 42848628.0 \tMSE Y1: 620710.9375\t PEHE: 400.0904589822468\n",
      "#1550. \tMSE Y0: 34184784.0 \tMSE Y1: 634550.375\t PEHE: 394.59578120029136\n",
      "#1600. \tMSE Y0: 13044931.0 \tMSE Y1: 588680.6875\t PEHE: 407.33672873100227\n",
      "#1650. \tMSE Y0: 17433832.0 \tMSE Y1: 672504.6875\t PEHE: 398.63746501763467\n",
      "#1700. \tMSE Y0: 29002074.0 \tMSE Y1: 610284.625\t PEHE: 395.2558288684292\n",
      "#1750. \tMSE Y0: 11639390.0 \tMSE Y1: 577316.25\t PEHE: 398.9044820945131\n",
      "#1800. \tMSE Y0: 8929479.0 \tMSE Y1: 545210.625\t PEHE: 394.496140097893\n",
      "#1850. \tMSE Y0: 27526840.0 \tMSE Y1: 608110.0625\t PEHE: 395.49626847344837\n",
      "#1900. \tMSE Y0: 8127797.0 \tMSE Y1: 514005.1875\t PEHE: 395.9574936384923\n",
      "#1950. \tMSE Y0: 11170935.0 \tMSE Y1: 672525.8125\t PEHE: 398.49957292475455\n",
      "#2000. \tMSE Y0: 10460697.0 \tMSE Y1: 624871.125\t PEHE: 394.3306492854934\n",
      "#2050. \tMSE Y0: 22393792.0 \tMSE Y1: 629503.875\t PEHE: 392.511369800342\n",
      "#2100. \tMSE Y0: 7843149.0 \tMSE Y1: 580182.25\t PEHE: 392.60249053724175\n",
      "#2150. \tMSE Y0: 17300178.0 \tMSE Y1: 570691.125\t PEHE: 392.51710520756865\n",
      "#2200. \tMSE Y0: 56714540.0 \tMSE Y1: 553777.3125\t PEHE: 395.1935827729713\n",
      "#2250. \tMSE Y0: 31516534.0 \tMSE Y1: 545400.3125\t PEHE: 396.15827689526765\n",
      "#2300. \tMSE Y0: 39988124.0 \tMSE Y1: 542219.5\t PEHE: 402.2166805943398\n",
      "#2350. \tMSE Y0: 52178248.0 \tMSE Y1: 633151.375\t PEHE: 391.3171563123049\n",
      "#2400. \tMSE Y0: 9613557.0 \tMSE Y1: 577934.375\t PEHE: 394.0565534057532\n",
      "#2450. \tMSE Y0: 18845646.0 \tMSE Y1: 590342.3125\t PEHE: 395.6166946161247\n",
      "#2500. \tMSE Y0: 27670012.0 \tMSE Y1: 526171.4375\t PEHE: 399.3818929541613\n",
      "#2550. \tMSE Y0: 18628388.0 \tMSE Y1: 574075.1875\t PEHE: 398.3060444268905\n",
      "#2600. \tMSE Y0: 8603037.0 \tMSE Y1: 574517.0625\t PEHE: 391.57517386280773\n",
      "#2650. \tMSE Y0: 13769874.0 \tMSE Y1: 523163.9375\t PEHE: 400.9120240787838\n",
      "#2700. \tMSE Y0: 10359946.0 \tMSE Y1: 476855.4375\t PEHE: 395.75337510347555\n",
      "#2750. \tMSE Y0: 6456836.0 \tMSE Y1: 500063.0\t PEHE: 397.61109258957407\n",
      "#2800. \tMSE Y0: 15735405.0 \tMSE Y1: 501300.3125\t PEHE: 402.1355548854785\n",
      "#2850. \tMSE Y0: 49793372.0 \tMSE Y1: 488773.21875\t PEHE: 394.4127629146516\n",
      "#2900. \tMSE Y0: 12743296.0 \tMSE Y1: 492713.5\t PEHE: 399.0631843275241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-6e0f22bf4061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# NN4 2 outcomes 4 shared layers(Dropout)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mnn4_multi_4s_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_nn4_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'4s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mnn4_multi_4s_all_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn4_multi_4s_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnn4_multi_4s_min_pehe_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn4_multi_4s_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-7b9e85c69d90>\u001b[0m in \u001b[0;36mrun_nn4_multi\u001b[0;34m(dataset_train, dataset_test, no_dropout, show_log, architecture)\u001b[0m\n\u001b[1;32m     77\u001b[0m                               \u001b[0mY_0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Treatment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                               \u001b[0mp_keep_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_keep_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                               p_keep_hidden: dropout_keep_hidden})\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 _, Y1_loss = sess.run([optim1, cost1], feed_dict= {\n",
      "\u001b[0;32m//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ox-dl-py3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn4_multi_4s_all_results = []      # NN4 2 outcomes 4 shared\n",
    "nn4_multi_2s_2i_all_results = []   # NN4 2 outcomes 2 shared, 2 idiosyncratic (total)\n",
    "nn4_multi_2s_4i_all_results = []   # NN4 2 outcomes 2 shared, 2 idiosyncratic (each)\n",
    "\n",
    "unos_generator = unos.UNOS_data('unos/unos_sample.csv')\n",
    "\n",
    "for i in range(global_config['n_experiments']):\n",
    "    print('Running Experiment {}/{}.'.format(i+1, global_config['n_experiments']))\n",
    "    \n",
    "    # Draw Data\n",
    "    dataset_all = unos_generator.draw_sample()\n",
    "    \n",
    "    # Use only the desire number of samples\n",
    "    dataset = dataset_all.loc[1:global_config['n_samples']]\n",
    "    \n",
    "    estimate_propensities(dataset)\n",
    "    \n",
    "    # Shuffle Dataset\n",
    "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Split Data into test and training set\n",
    "    dataset_train = dataset[0:global_config['n_train']]\n",
    "    dataset_test = dataset[global_config['n_train']:]\n",
    "    \n",
    "    # NN4 2 outcomes 4 shared layers(Dropout)\n",
    "    nn4_multi_4s_results = run_nn4_multi(dataset_train, dataset_test, architecture='4s', show_log=True)\n",
    "    nn4_multi_4s_all_results.append(nn4_multi_4s_results)    \n",
    "    nn4_multi_4s_min_pehe_train =  np.min(nn4_multi_4s_results['pehe_train_vals'])\n",
    "    nn4_multi_4s_min_pehe_test =  np.min(nn4_multi_4s_results['pehe_test_vals'])\n",
    "    \n",
    "    # NN4 2 outcomes 2 shared layers, 1 idiosyncratic per outcome (Dropout)\n",
    "    #nn4_multi_2s_2i_results = run_nn4_multi(dataset_train, dataset_test, architecture='4s_2i')\n",
    "    #nn4_multi_2s_2i_all_results.append(nn4_multi_2s_2i_results)    \n",
    "    #nn4_multi_2s_2i_min_pehe_train =  np.min(nn4_multi_2s_2i_results['pehe_train_vals'])\n",
    "    #nn4_multi_2s_2i_min_pehe_test =  np.min(nn4_multi_2s_2i_results['pehe_test_vals'])\n",
    "    \n",
    "    # NN4 2 outcomes 2 shared layers, 2 idiosyncratic per outcome (Dropout)\n",
    "    #nn4_multi_2s_4i_results = run_nn4_multi(dataset_train, dataset_test, architecture='4s_4i')\n",
    "    #nn4_multi_2s_4i_all_results.append(nn4_multi_2s_4i_results)    \n",
    "    #nn4_multi_2s_4i_min_pehe_train =  np.min(nn4_multi_2s_4i_results['pehe_train_vals'])\n",
    "    #nn4_multi_2s_4i_min_pehe_test =  np.min(nn4_multi_2s_4i_results['pehe_test_vals'])\n",
    "    \n",
    "    # NN4 2 outcomes (PBD)\n",
    "    #nn4_pbd_results = run_nn4_pbd(dataset_train, dataset_test)\n",
    "    #nn4_pbd_all_results.append(nn4_pbd_results)    \n",
    "    #nn4_pbd_min_pehe_train =  np.min(nn4_pbd_results['pehe_train_vals'])\n",
    "    #nn4_pbd_min_pehe_test =  np.min(nn4_pbd_results['pehe_test_vals'])\n",
    "    \n",
    "\n",
    "    #print('\\tMin. PEHE (Train). NN4: {}\\t NN4 (no Dropout): {}\\t NN4 Dropout: {}\\t NN4 PBD: {}'.format(nn4_min_pehe_train, nn4_no_dropout_min_pehe_train, nn4_dropout_min_pehe_train, nn4_pbd_min_pehe_train))\n",
    "    #print('\\tMin. PEHE (Test). NN4: {}\\t NN4 (no Dropout): {}\\t NN4 Dropout: {}\\t NN4 PBD: {}'.format(nn4_min_pehe_test, nn4_no_dropout_min_pehe_test, nn4_dropout_min_pehe_test, nn4_pbd_min_pehe_test))\n",
    "    \n",
    "    # Only 2 Outcomes\n",
    "    print('\\tMin. PEHE (Train). NN4 Multi 4s: {}\\t NN4 Multi 2s 2i: {}\\t NN4 Multi 2s 4i: {}'.format(nn4_multi_4s_min_pehe_train, nn4_multi_2s_2i_min_pehe_train,nn4_multi_2s_4i_min_pehe_train ))\n",
    "    print('\\tMin. PEHE (Test). NN4 Multi 4s: {}\\t NN4 Multi 2s 2i: {}\\t NN4 Multi 2s 4i: {}'.format(nn4_multi_4s_min_pehe_test, nn4_multi_2s_2i_min_pehe_test,nn4_multi_2s_4i_min_pehe_test ))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Result Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle results into file (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine results\n",
    "results_combined = {\n",
    "    'NN4' : nn4_all_results,\n",
    "    'NN4 No Dropout': nn4_no_dropout_all_results,\n",
    "    'NN4 2 Outcomes': nn4_dropout_all_results,\n",
    "    'NN4 PBD': nn4_pbd_all_results\n",
    "}\n",
    "\n",
    "filename = '16-06-17-results.dat'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(results_combined, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEHE TRAIN\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn4_dropout_all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c259b5bec8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_no_dropout_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_dropout_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_pbd_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn4_dropout_all_results' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"PEHE TRAIN\")\n",
    "print(['%.2f' % np.min(res['pehe_train_vals']) for res in nn4_all_results])\n",
    "print(['%.2f' % np.min(res['pehe_train_vals']) for res in nn4_no_dropout_all_results])\n",
    "print(['%.2f' % np.min(res['pehe_train_vals']) for res in nn4_dropout_all_results])\n",
    "print(['%.2f' % np.min(res['pehe_train_vals']) for res in nn4_pbd_all_results])\n",
    "\n",
    "print(\"\\nPEHE TEST\")\n",
    "print(['%.2f' % np.min(res['pehe_test_vals']) for res in nn4_all_results])\n",
    "print(['%.2f' % np.min(res['pehe_test_vals']) for res in nn4_no_dropout_all_results])\n",
    "print(['%.2f' % np.min(res['pehe_test_vals']) for res in nn4_dropout_all_results])\n",
    "print(['%.2f' % np.min(res['pehe_test_vals']) for res in nn4_pbd_all_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn4_dropout_all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5c1dbdd93f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmin_pehes_nn4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmin_pehes_nn4_no_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_no_dropout_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmin_pehes_nn4_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_dropout_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmin_pehes_nn4_pbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn4_pbd_all_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn4_dropout_all_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "min_pehes_nn4 = [np.min(res['pehe_train_vals']) for res in nn4_all_results]\n",
    "min_pehes_nn4_no_dropout = [np.min(res['pehe_train_vals']) for res in nn4_no_dropout_all_results]\n",
    "min_pehes_nn4_dropout = [np.min(res['pehe_train_vals']) for res in nn4_dropout_all_results]\n",
    "min_pehes_nn4_pbd = [np.min(res['pehe_train_vals']) for res in nn4_pbd_all_results]\n",
    "\n",
    "data = [min_pehes_nn4, min_pehes_nn4_no_dropout, min_pehes_nn4_dropout, min_pehes_nn4_pbd]\n",
    "labels = ['NN4 (with Dropout)', 'NN4 (no Dropout)', 'NN4 2Out (with Dropout)', 'NN4 2Out (PBD)']\n",
    "\n",
    "plt.boxplot(data, labels=labels)\n",
    "plt.title('PEHE Values (Train)')\n",
    "plt.ylabel('PEHE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Test\n",
    "min_pehes_nn4 = [np.min(res['pehe_test_vals']) for res in nn4_all_results]\n",
    "min_pehes_nn4_no_dropout = [np.min(res['pehe_test_vals']) for res in nn4_no_dropout_all_results]\n",
    "min_pehes_nn4_dropout = [np.min(res['pehe_test_vals']) for res in nn4_dropout_all_results]\n",
    "min_pehes_nn4_pbd = [np.min(res['pehe_test_vals']) for res in nn4_pbd_all_results]\n",
    "\n",
    "data = [min_pehes_nn4, min_pehes_nn4_no_dropout, min_pehes_nn4_dropout, min_pehes_nn4_pbd]\n",
    "labels = ['NN4 (with Dropout)', 'NN4 (no Dropout)', 'NN4 2Out (with Dropout)', 'NN4 2Out (PBD)']\n",
    "\n",
    "plt.boxplot(data, labels=labels)\n",
    "plt.title('PEHE Values (TEST)')\n",
    "plt.ylabel('PEHE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEHE Values (over epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fdaae328c269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PEHE: NN-4 (Treatment as Feature) vs. NN-4 Dropout (2 outcomes) vs. NN-4 PBD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn4_all_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NN-4 (Train)'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn4_all_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_test_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NN-4 (Test)'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn4_no_dropout_all_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pehe_train_vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NN-4 (Train)'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plt.title('PEHE: NN-4 (Treatment as Feature) vs. NN-4 Dropout (2 outcomes) vs. NN-4 PBD')\n",
    "plt.plot(nn4_all_results[0]['pehe_train_vals'], label='NN-4 (Train)',  color='r')\n",
    "plt.plot(nn4_all_results[0]['pehe_test_vals'], label='NN-4 (Test)',  color='r', linestyle=':')\n",
    "\n",
    "plt.plot(nn4_no_dropout_all_results[0]['pehe_train_vals'], label='NN-4 (Train)',  color='b')\n",
    "plt.plot(nn4_no_dropout_all_results[0]['pehe_test_vals'], label='NN-4 (Test)',  color='b', linestyle=':')\n",
    "#plt.plot(nn4_all_pehe_train[4], label='NN-4 (Train) 2',  color='b')\n",
    "#plt.plot(nn4_all_pehe_test[4], label='NN-4 (Test) 2',  color='b', linestyle=':')\n",
    "\n",
    "#plt.plot(nn4_dropout_pehe_train, label='NN-4 Dropout (Train)',  color='b')\n",
    "#plt.plot(nn4_dropout_pehe_test, label='NN-4 Dropout (Test)',  color='b', linestyle=':')\n",
    "#plt.plot(nn4_pbd_pehe_train, label='NN-4 PBD (Train)',  color='g')\n",
    "#plt.plot(nn4_pbd_pehe_test, label='NN-4 PBD (Test)',  color='g', linestyle=':')\n",
    "\n",
    "plt.ylabel('PEHE')\n",
    "plt.xlabel('# Iteration')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.title('NN-4 (Treatment as Feature)')\n",
    "#plt.plot(nn4_mses_train, label='MSE (Train)')\n",
    "#plt.ylabel('MSE')\n",
    "#plt.xlabel('# Iteration')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()\n",
    "\n",
    "#plt.title('NN-4 Dropout (2 outcomes)')\n",
    "#plt.plot(nn4_dropout_mses_train_0, label='MSE Y0')\n",
    "#plt.plot(nn4_dropout_mses_train_1, label='MSE Y1')\n",
    "#plt.ylabel('MSE')\n",
    "#plt.xlabel('# Iteration')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()\n",
    "\n",
    "#plt.title('NN-4 PBD')\n",
    "#plt.plot(nn4_pbd_mses_train_0, label='MSE Y0')\n",
    "#plt.plot(nn4_pbd_mses_train_1, label='MSE Y1')\n",
    "#plt.ylabel('MSE')\n",
    "#plt.xlabel('# Iteration')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
